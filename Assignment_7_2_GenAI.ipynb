{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJ2SbvJ3TEnbYNjoliOmtZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MunjaSangeetha/Generative-AI/blob/main/Assignment_7_2_GenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "M.Sangeetha\n",
        "2303A52088\n",
        "Generative AI\n",
        "Assignment - 7.2"
      ],
      "metadata": {
        "id": "kf20xN6bmwI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 2: Load the dataset (replace with the actual dataset path)\n",
        "# Make sure to replace 'path_to_your_dataset.csv' with the actual path to your dataset.\n",
        "dataset = pd.read_csv('/content/diabetes (1).csv')  # Load dataset\n",
        "\n",
        "# Step 3: Preprocess the data\n",
        "# Assuming 'Outcome' is the target variable (1 for diabetic, 0 for non-diabetic)\n",
        "X = dataset.drop(columns=['Outcome'])  # Features\n",
        "y = dataset['Outcome']  # Target variable\n",
        "\n",
        "# Normalize the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Build the ANN model\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer and Hidden Layer 1 (10 neurons, tanh activation)\n",
        "model.add(Dense(10, input_dim=X_train.shape[1], activation='tanh'))\n",
        "\n",
        "# Hidden Layer 2 (15 neurons, tanh activation)\n",
        "model.add(Dense(15, activation='tanh'))\n",
        "\n",
        "# Hidden Layer 3 (20 neurons, tanh activation)\n",
        "model.add(Dense(20, activation='tanh'))\n",
        "\n",
        "# Hidden Layer 4 (10 neurons, tanh activation)\n",
        "model.add(Dense(10, activation='tanh'))\n",
        "\n",
        "# Hidden Layer 5 (5 neurons, tanh activation)\n",
        "model.add(Dense(5, activation='tanh'))\n",
        "\n",
        "# Output Layer (1 neuron for binary classification)\n",
        "model.add(Dense(1, activation='sigmoid'))  # Sigmoid activation for binary classification\n",
        "\n",
        "# Step 5: Compile the model with Adam optimizer, accuracy metric, and binary crossentropy loss function\n",
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 6: Train the model (epochs=250, batch_size=32)\n",
        "history = model.fit(X_train, y_train, epochs=250, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Step 7: Evaluate the model on the test data\n",
        "train_loss, train_accuracy = model.evaluate(X_train, y_train)\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Output training and testing accuracy\n",
        "print(f'Training Accuracy: {train_accuracy}')\n",
        "print(f'Testing Accuracy: {test_accuracy}')\n",
        "\n",
        "# Step 8: Save the model to a .h5 file\n",
        "model.save('diabetes_diagnosis_model.h5')\n",
        "\n",
        "# Step 9: (Evaluation) Calculate confusion matrix and classification metrics\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Precision, Recall, and F1-Score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1-Score: {f1}')\n",
        "\n",
        "# Plotting confusion matrix\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Diabetic', 'Diabetic'], yticklabels=['Non-Diabetic', 'Diabetic'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "# Step 10: (Deployment) Load the saved model for future predictions\n",
        "from keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = load_model('diabetes_diagnosis_model.h5')\n",
        "\n",
        "# Example prediction on new data\n",
        "# Replace these placeholder values with actual values for a new patient\n",
        "# The number of values here should match the number of features (e.g., 10 values for 10 features)\n",
        "# Example prediction on new data\n",
        "# Replace these placeholder values with actual values for a new patient\n",
        "# The number of values here should match the number of features (e.g., 8 values for 8 features)\n",
        "\n",
        "new_data = [[5.1, 3.5, 1.4, 0.2, 6.0, 3.0, 4.5, 1.5]]  # Replace with actual new feature values (8 features)\n",
        "\n",
        "# Scale the new data using the same scaler used during training\n",
        "new_data = scaler.transform(new_data)\n",
        "\n",
        "# Make the prediction\n",
        "predicted_outcome = loaded_model.predict(new_data)\n",
        "\n",
        "# Convert the prediction to 0 or 1 (Diabetic or Non-Diabetic)\n",
        "predicted_class = (predicted_outcome > 0.5).astype(int)\n",
        "\n",
        "# Print the predicted class (0: Non-Diabetic, 1: Diabetic)\n",
        "print(f'Predicted Class (0: Non-Diabetic, 1: Diabetic): {predicted_class[0][0]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jeNo2gU6mE8f",
        "outputId": "ab78daf8-9e4e-41d3-ce6b-d107e33f6a05"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5385 - loss: 0.6880 - val_accuracy: 0.7468 - val_loss: 0.5712\n",
            "Epoch 2/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7455 - loss: 0.5766 - val_accuracy: 0.7662 - val_loss: 0.5196\n",
            "Epoch 3/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7594 - loss: 0.5241 - val_accuracy: 0.7727 - val_loss: 0.4969\n",
            "Epoch 4/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7681 - loss: 0.5024 - val_accuracy: 0.7857 - val_loss: 0.4900\n",
            "Epoch 5/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7757 - loss: 0.4858 - val_accuracy: 0.7727 - val_loss: 0.4916\n",
            "Epoch 6/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7922 - loss: 0.4636 - val_accuracy: 0.7857 - val_loss: 0.4868\n",
            "Epoch 7/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7967 - loss: 0.4767 - val_accuracy: 0.7792 - val_loss: 0.4907\n",
            "Epoch 8/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7972 - loss: 0.4705 - val_accuracy: 0.7727 - val_loss: 0.4974\n",
            "Epoch 9/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7926 - loss: 0.4617 - val_accuracy: 0.7727 - val_loss: 0.4995\n",
            "Epoch 10/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7718 - loss: 0.4787 - val_accuracy: 0.7662 - val_loss: 0.4961\n",
            "Epoch 11/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7729 - loss: 0.4754 - val_accuracy: 0.7727 - val_loss: 0.4929\n",
            "Epoch 12/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7982 - loss: 0.4625 - val_accuracy: 0.7727 - val_loss: 0.4944\n",
            "Epoch 13/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7512 - loss: 0.5028 - val_accuracy: 0.7662 - val_loss: 0.4977\n",
            "Epoch 14/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7742 - loss: 0.4860 - val_accuracy: 0.7662 - val_loss: 0.5012\n",
            "Epoch 15/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8107 - loss: 0.4532 - val_accuracy: 0.7727 - val_loss: 0.5073\n",
            "Epoch 16/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8108 - loss: 0.4473 - val_accuracy: 0.7662 - val_loss: 0.5102\n",
            "Epoch 17/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8136 - loss: 0.4535 - val_accuracy: 0.7662 - val_loss: 0.5050\n",
            "Epoch 18/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7990 - loss: 0.4742 - val_accuracy: 0.7662 - val_loss: 0.5139\n",
            "Epoch 19/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7728 - loss: 0.4697 - val_accuracy: 0.7662 - val_loss: 0.5083\n",
            "Epoch 20/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7932 - loss: 0.4387 - val_accuracy: 0.7662 - val_loss: 0.5122\n",
            "Epoch 21/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8075 - loss: 0.4391 - val_accuracy: 0.7597 - val_loss: 0.5152\n",
            "Epoch 22/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7949 - loss: 0.4642 - val_accuracy: 0.7662 - val_loss: 0.5136\n",
            "Epoch 23/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8284 - loss: 0.4160 - val_accuracy: 0.7597 - val_loss: 0.5113\n",
            "Epoch 24/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7962 - loss: 0.4469 - val_accuracy: 0.7662 - val_loss: 0.5094\n",
            "Epoch 25/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8115 - loss: 0.4370 - val_accuracy: 0.7532 - val_loss: 0.5142\n",
            "Epoch 26/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8090 - loss: 0.4467 - val_accuracy: 0.7662 - val_loss: 0.5146\n",
            "Epoch 27/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8109 - loss: 0.4558 - val_accuracy: 0.7532 - val_loss: 0.5117\n",
            "Epoch 28/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8155 - loss: 0.4211 - val_accuracy: 0.7662 - val_loss: 0.5059\n",
            "Epoch 29/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8145 - loss: 0.4536 - val_accuracy: 0.7532 - val_loss: 0.5040\n",
            "Epoch 30/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8025 - loss: 0.4381 - val_accuracy: 0.7468 - val_loss: 0.5155\n",
            "Epoch 31/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7919 - loss: 0.4620 - val_accuracy: 0.7532 - val_loss: 0.5147\n",
            "Epoch 32/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8047 - loss: 0.4467 - val_accuracy: 0.7532 - val_loss: 0.5123\n",
            "Epoch 33/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8265 - loss: 0.4286 - val_accuracy: 0.7468 - val_loss: 0.5118\n",
            "Epoch 34/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8167 - loss: 0.4266 - val_accuracy: 0.7403 - val_loss: 0.5104\n",
            "Epoch 35/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8261 - loss: 0.4062 - val_accuracy: 0.7468 - val_loss: 0.5167\n",
            "Epoch 36/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8110 - loss: 0.4412 - val_accuracy: 0.7403 - val_loss: 0.5238\n",
            "Epoch 37/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8259 - loss: 0.4198 - val_accuracy: 0.7662 - val_loss: 0.5077\n",
            "Epoch 38/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7913 - loss: 0.4582 - val_accuracy: 0.7403 - val_loss: 0.5166\n",
            "Epoch 39/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8145 - loss: 0.4367 - val_accuracy: 0.7338 - val_loss: 0.5133\n",
            "Epoch 40/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8325 - loss: 0.4139 - val_accuracy: 0.7532 - val_loss: 0.5119\n",
            "Epoch 41/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8277 - loss: 0.4159 - val_accuracy: 0.7532 - val_loss: 0.5114\n",
            "Epoch 42/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7872 - loss: 0.4516 - val_accuracy: 0.7597 - val_loss: 0.5138\n",
            "Epoch 43/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8239 - loss: 0.4352 - val_accuracy: 0.7532 - val_loss: 0.5080\n",
            "Epoch 44/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7805 - loss: 0.4722 - val_accuracy: 0.7468 - val_loss: 0.5194\n",
            "Epoch 45/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8112 - loss: 0.4331 - val_accuracy: 0.7532 - val_loss: 0.5217\n",
            "Epoch 46/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8171 - loss: 0.4181 - val_accuracy: 0.7468 - val_loss: 0.5243\n",
            "Epoch 47/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8012 - loss: 0.4364 - val_accuracy: 0.7597 - val_loss: 0.5138\n",
            "Epoch 48/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8132 - loss: 0.4463 - val_accuracy: 0.7597 - val_loss: 0.5137\n",
            "Epoch 49/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8207 - loss: 0.4126 - val_accuracy: 0.7532 - val_loss: 0.5194\n",
            "Epoch 50/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7946 - loss: 0.4401 - val_accuracy: 0.7597 - val_loss: 0.5153\n",
            "Epoch 51/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8062 - loss: 0.4280 - val_accuracy: 0.7597 - val_loss: 0.5178\n",
            "Epoch 52/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7974 - loss: 0.4545 - val_accuracy: 0.7532 - val_loss: 0.5215\n",
            "Epoch 53/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8426 - loss: 0.3838 - val_accuracy: 0.7597 - val_loss: 0.5167\n",
            "Epoch 54/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8252 - loss: 0.4150 - val_accuracy: 0.7468 - val_loss: 0.5282\n",
            "Epoch 55/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8220 - loss: 0.4228 - val_accuracy: 0.7532 - val_loss: 0.5166\n",
            "Epoch 56/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8180 - loss: 0.4450 - val_accuracy: 0.7727 - val_loss: 0.5206\n",
            "Epoch 57/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8229 - loss: 0.4279 - val_accuracy: 0.7597 - val_loss: 0.5169\n",
            "Epoch 58/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8159 - loss: 0.4196 - val_accuracy: 0.7597 - val_loss: 0.5210\n",
            "Epoch 59/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8146 - loss: 0.4254 - val_accuracy: 0.7597 - val_loss: 0.5184\n",
            "Epoch 60/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8140 - loss: 0.4255 - val_accuracy: 0.7597 - val_loss: 0.5220\n",
            "Epoch 61/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7831 - loss: 0.4853 - val_accuracy: 0.7468 - val_loss: 0.5235\n",
            "Epoch 62/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8191 - loss: 0.4362 - val_accuracy: 0.7468 - val_loss: 0.5281\n",
            "Epoch 63/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8100 - loss: 0.4454 - val_accuracy: 0.7597 - val_loss: 0.5234\n",
            "Epoch 64/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8278 - loss: 0.4073 - val_accuracy: 0.7403 - val_loss: 0.5277\n",
            "Epoch 65/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8094 - loss: 0.4201 - val_accuracy: 0.7597 - val_loss: 0.5213\n",
            "Epoch 66/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8180 - loss: 0.4118 - val_accuracy: 0.7532 - val_loss: 0.5286\n",
            "Epoch 67/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8174 - loss: 0.4364 - val_accuracy: 0.7532 - val_loss: 0.5241\n",
            "Epoch 68/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8183 - loss: 0.4319 - val_accuracy: 0.7662 - val_loss: 0.5265\n",
            "Epoch 69/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8360 - loss: 0.4028 - val_accuracy: 0.7662 - val_loss: 0.5193\n",
            "Epoch 70/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8219 - loss: 0.4181 - val_accuracy: 0.7532 - val_loss: 0.5261\n",
            "Epoch 71/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8321 - loss: 0.4011 - val_accuracy: 0.7662 - val_loss: 0.5168\n",
            "Epoch 72/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8332 - loss: 0.4049 - val_accuracy: 0.7662 - val_loss: 0.5261\n",
            "Epoch 73/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8179 - loss: 0.4453 - val_accuracy: 0.7468 - val_loss: 0.5341\n",
            "Epoch 74/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8142 - loss: 0.4360 - val_accuracy: 0.7662 - val_loss: 0.5215\n",
            "Epoch 75/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7969 - loss: 0.4463 - val_accuracy: 0.7597 - val_loss: 0.5259\n",
            "Epoch 76/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8143 - loss: 0.4285 - val_accuracy: 0.7597 - val_loss: 0.5276\n",
            "Epoch 77/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8212 - loss: 0.4044 - val_accuracy: 0.7597 - val_loss: 0.5287\n",
            "Epoch 78/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8187 - loss: 0.4178 - val_accuracy: 0.7662 - val_loss: 0.5304\n",
            "Epoch 79/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8209 - loss: 0.4116 - val_accuracy: 0.7662 - val_loss: 0.5271\n",
            "Epoch 80/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7968 - loss: 0.4378 - val_accuracy: 0.7468 - val_loss: 0.5222\n",
            "Epoch 81/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8027 - loss: 0.4360 - val_accuracy: 0.7662 - val_loss: 0.5258\n",
            "Epoch 82/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8413 - loss: 0.3930 - val_accuracy: 0.7597 - val_loss: 0.5237\n",
            "Epoch 83/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8017 - loss: 0.4523 - val_accuracy: 0.7727 - val_loss: 0.5258\n",
            "Epoch 84/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8169 - loss: 0.4258 - val_accuracy: 0.7468 - val_loss: 0.5288\n",
            "Epoch 85/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8190 - loss: 0.3988 - val_accuracy: 0.7662 - val_loss: 0.5237\n",
            "Epoch 86/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8188 - loss: 0.4257 - val_accuracy: 0.7597 - val_loss: 0.5183\n",
            "Epoch 87/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8227 - loss: 0.4119 - val_accuracy: 0.7532 - val_loss: 0.5253\n",
            "Epoch 88/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8180 - loss: 0.4358 - val_accuracy: 0.7597 - val_loss: 0.5264\n",
            "Epoch 89/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8305 - loss: 0.4061 - val_accuracy: 0.7727 - val_loss: 0.5245\n",
            "Epoch 90/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8228 - loss: 0.4193 - val_accuracy: 0.7662 - val_loss: 0.5298\n",
            "Epoch 91/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8441 - loss: 0.3853 - val_accuracy: 0.7468 - val_loss: 0.5365\n",
            "Epoch 92/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8330 - loss: 0.3898 - val_accuracy: 0.7597 - val_loss: 0.5318\n",
            "Epoch 93/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8343 - loss: 0.4074 - val_accuracy: 0.7792 - val_loss: 0.5240\n",
            "Epoch 94/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8071 - loss: 0.4289 - val_accuracy: 0.7727 - val_loss: 0.5277\n",
            "Epoch 95/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8108 - loss: 0.4256 - val_accuracy: 0.7727 - val_loss: 0.5296\n",
            "Epoch 96/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8285 - loss: 0.4085 - val_accuracy: 0.7597 - val_loss: 0.5316\n",
            "Epoch 97/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8232 - loss: 0.3967 - val_accuracy: 0.7532 - val_loss: 0.5292\n",
            "Epoch 98/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8273 - loss: 0.3766 - val_accuracy: 0.7662 - val_loss: 0.5252\n",
            "Epoch 99/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8147 - loss: 0.4249 - val_accuracy: 0.7727 - val_loss: 0.5294\n",
            "Epoch 100/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7987 - loss: 0.4325 - val_accuracy: 0.7597 - val_loss: 0.5398\n",
            "Epoch 101/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8356 - loss: 0.4042 - val_accuracy: 0.7792 - val_loss: 0.5311\n",
            "Epoch 102/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8382 - loss: 0.3781 - val_accuracy: 0.7597 - val_loss: 0.5452\n",
            "Epoch 103/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8268 - loss: 0.3914 - val_accuracy: 0.7792 - val_loss: 0.5322\n",
            "Epoch 104/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8367 - loss: 0.3919 - val_accuracy: 0.7727 - val_loss: 0.5405\n",
            "Epoch 105/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8254 - loss: 0.3888 - val_accuracy: 0.7857 - val_loss: 0.5329\n",
            "Epoch 106/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8221 - loss: 0.4078 - val_accuracy: 0.7792 - val_loss: 0.5271\n",
            "Epoch 107/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8277 - loss: 0.3833 - val_accuracy: 0.7727 - val_loss: 0.5316\n",
            "Epoch 108/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8154 - loss: 0.4032 - val_accuracy: 0.7662 - val_loss: 0.5365\n",
            "Epoch 109/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8321 - loss: 0.3903 - val_accuracy: 0.7727 - val_loss: 0.5366\n",
            "Epoch 110/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8304 - loss: 0.4137 - val_accuracy: 0.7597 - val_loss: 0.5439\n",
            "Epoch 111/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8521 - loss: 0.3619 - val_accuracy: 0.7727 - val_loss: 0.5307\n",
            "Epoch 112/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8270 - loss: 0.4094 - val_accuracy: 0.7468 - val_loss: 0.5379\n",
            "Epoch 113/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8268 - loss: 0.3888 - val_accuracy: 0.7792 - val_loss: 0.5301\n",
            "Epoch 114/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8311 - loss: 0.3778 - val_accuracy: 0.7532 - val_loss: 0.5390\n",
            "Epoch 115/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8545 - loss: 0.3662 - val_accuracy: 0.7597 - val_loss: 0.5334\n",
            "Epoch 116/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8108 - loss: 0.4159 - val_accuracy: 0.7468 - val_loss: 0.5392\n",
            "Epoch 117/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8478 - loss: 0.3655 - val_accuracy: 0.7727 - val_loss: 0.5351\n",
            "Epoch 118/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8335 - loss: 0.3921 - val_accuracy: 0.7662 - val_loss: 0.5323\n",
            "Epoch 119/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8403 - loss: 0.3597 - val_accuracy: 0.7662 - val_loss: 0.5380\n",
            "Epoch 120/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8372 - loss: 0.3777 - val_accuracy: 0.7727 - val_loss: 0.5304\n",
            "Epoch 121/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8475 - loss: 0.3652 - val_accuracy: 0.7468 - val_loss: 0.5534\n",
            "Epoch 122/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8163 - loss: 0.3975 - val_accuracy: 0.7727 - val_loss: 0.5437\n",
            "Epoch 123/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8455 - loss: 0.3630 - val_accuracy: 0.7792 - val_loss: 0.5417\n",
            "Epoch 124/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8302 - loss: 0.3853 - val_accuracy: 0.7727 - val_loss: 0.5425\n",
            "Epoch 125/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8211 - loss: 0.4019 - val_accuracy: 0.7727 - val_loss: 0.5482\n",
            "Epoch 126/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8113 - loss: 0.3961 - val_accuracy: 0.7662 - val_loss: 0.5495\n",
            "Epoch 127/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8315 - loss: 0.3698 - val_accuracy: 0.7662 - val_loss: 0.5522\n",
            "Epoch 128/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8142 - loss: 0.4018 - val_accuracy: 0.7597 - val_loss: 0.5561\n",
            "Epoch 129/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8482 - loss: 0.3728 - val_accuracy: 0.7727 - val_loss: 0.5430\n",
            "Epoch 130/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8433 - loss: 0.3619 - val_accuracy: 0.7727 - val_loss: 0.5451\n",
            "Epoch 131/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8020 - loss: 0.4014 - val_accuracy: 0.7662 - val_loss: 0.5513\n",
            "Epoch 132/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8439 - loss: 0.3627 - val_accuracy: 0.7727 - val_loss: 0.5513\n",
            "Epoch 133/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8541 - loss: 0.3341 - val_accuracy: 0.7727 - val_loss: 0.5496\n",
            "Epoch 134/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8311 - loss: 0.3659 - val_accuracy: 0.7727 - val_loss: 0.5548\n",
            "Epoch 135/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8305 - loss: 0.3616 - val_accuracy: 0.7597 - val_loss: 0.5576\n",
            "Epoch 136/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8352 - loss: 0.3578 - val_accuracy: 0.7727 - val_loss: 0.5524\n",
            "Epoch 137/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8175 - loss: 0.4039 - val_accuracy: 0.7597 - val_loss: 0.5433\n",
            "Epoch 138/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8175 - loss: 0.3728 - val_accuracy: 0.7597 - val_loss: 0.5495\n",
            "Epoch 139/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8214 - loss: 0.3780 - val_accuracy: 0.7662 - val_loss: 0.5522\n",
            "Epoch 140/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8202 - loss: 0.3761 - val_accuracy: 0.7662 - val_loss: 0.5524\n",
            "Epoch 141/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8344 - loss: 0.3646 - val_accuracy: 0.7597 - val_loss: 0.5586\n",
            "Epoch 142/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8538 - loss: 0.3427 - val_accuracy: 0.7532 - val_loss: 0.5666\n",
            "Epoch 143/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8441 - loss: 0.3577 - val_accuracy: 0.7662 - val_loss: 0.5594\n",
            "Epoch 144/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8293 - loss: 0.3656 - val_accuracy: 0.7532 - val_loss: 0.5641\n",
            "Epoch 145/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8215 - loss: 0.3778 - val_accuracy: 0.7597 - val_loss: 0.5578\n",
            "Epoch 146/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8370 - loss: 0.3817 - val_accuracy: 0.7532 - val_loss: 0.5608\n",
            "Epoch 147/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8197 - loss: 0.3806 - val_accuracy: 0.7597 - val_loss: 0.5619\n",
            "Epoch 148/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8345 - loss: 0.3596 - val_accuracy: 0.7662 - val_loss: 0.5707\n",
            "Epoch 149/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8375 - loss: 0.3616 - val_accuracy: 0.7532 - val_loss: 0.5674\n",
            "Epoch 150/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8411 - loss: 0.3823 - val_accuracy: 0.7597 - val_loss: 0.5781\n",
            "Epoch 151/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8298 - loss: 0.3717 - val_accuracy: 0.7532 - val_loss: 0.5718\n",
            "Epoch 152/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8597 - loss: 0.3323 - val_accuracy: 0.7468 - val_loss: 0.5694\n",
            "Epoch 153/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8194 - loss: 0.3727 - val_accuracy: 0.7468 - val_loss: 0.5708\n",
            "Epoch 154/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8533 - loss: 0.3311 - val_accuracy: 0.7468 - val_loss: 0.5751\n",
            "Epoch 155/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8544 - loss: 0.3442 - val_accuracy: 0.7532 - val_loss: 0.5746\n",
            "Epoch 156/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8432 - loss: 0.3412 - val_accuracy: 0.7468 - val_loss: 0.5719\n",
            "Epoch 157/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8462 - loss: 0.3512 - val_accuracy: 0.7468 - val_loss: 0.5775\n",
            "Epoch 158/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8420 - loss: 0.3503 - val_accuracy: 0.7532 - val_loss: 0.5826\n",
            "Epoch 159/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8456 - loss: 0.3549 - val_accuracy: 0.7532 - val_loss: 0.5918\n",
            "Epoch 160/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8362 - loss: 0.3521 - val_accuracy: 0.7468 - val_loss: 0.5799\n",
            "Epoch 161/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8524 - loss: 0.3514 - val_accuracy: 0.7468 - val_loss: 0.5868\n",
            "Epoch 162/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8524 - loss: 0.3341 - val_accuracy: 0.7532 - val_loss: 0.5889\n",
            "Epoch 163/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8726 - loss: 0.2940 - val_accuracy: 0.7468 - val_loss: 0.5903\n",
            "Epoch 164/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8378 - loss: 0.3560 - val_accuracy: 0.7597 - val_loss: 0.5799\n",
            "Epoch 165/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8409 - loss: 0.3507 - val_accuracy: 0.7468 - val_loss: 0.5788\n",
            "Epoch 166/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8605 - loss: 0.3317 - val_accuracy: 0.7468 - val_loss: 0.5941\n",
            "Epoch 167/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8566 - loss: 0.3353 - val_accuracy: 0.7468 - val_loss: 0.5893\n",
            "Epoch 168/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8718 - loss: 0.3338 - val_accuracy: 0.7468 - val_loss: 0.6015\n",
            "Epoch 169/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8289 - loss: 0.3463 - val_accuracy: 0.7468 - val_loss: 0.5961\n",
            "Epoch 170/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8448 - loss: 0.3240 - val_accuracy: 0.7468 - val_loss: 0.6076\n",
            "Epoch 171/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8616 - loss: 0.2991 - val_accuracy: 0.7532 - val_loss: 0.6015\n",
            "Epoch 172/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8607 - loss: 0.3223 - val_accuracy: 0.7532 - val_loss: 0.5995\n",
            "Epoch 173/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8425 - loss: 0.3510 - val_accuracy: 0.7532 - val_loss: 0.5948\n",
            "Epoch 174/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8632 - loss: 0.3038 - val_accuracy: 0.7468 - val_loss: 0.6022\n",
            "Epoch 175/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8459 - loss: 0.3441 - val_accuracy: 0.7468 - val_loss: 0.6080\n",
            "Epoch 176/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8428 - loss: 0.3266 - val_accuracy: 0.7468 - val_loss: 0.6051\n",
            "Epoch 177/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8528 - loss: 0.3346 - val_accuracy: 0.7468 - val_loss: 0.6086\n",
            "Epoch 178/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8556 - loss: 0.3268 - val_accuracy: 0.7468 - val_loss: 0.6055\n",
            "Epoch 179/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8603 - loss: 0.3206 - val_accuracy: 0.7532 - val_loss: 0.6044\n",
            "Epoch 180/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8434 - loss: 0.3420 - val_accuracy: 0.7468 - val_loss: 0.6137\n",
            "Epoch 181/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8720 - loss: 0.3167 - val_accuracy: 0.7468 - val_loss: 0.6145\n",
            "Epoch 182/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8530 - loss: 0.3367 - val_accuracy: 0.7468 - val_loss: 0.6197\n",
            "Epoch 183/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8562 - loss: 0.3341 - val_accuracy: 0.7532 - val_loss: 0.6183\n",
            "Epoch 184/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8305 - loss: 0.3617 - val_accuracy: 0.7532 - val_loss: 0.6241\n",
            "Epoch 185/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8509 - loss: 0.3392 - val_accuracy: 0.7532 - val_loss: 0.6247\n",
            "Epoch 186/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8486 - loss: 0.3285 - val_accuracy: 0.7532 - val_loss: 0.6196\n",
            "Epoch 187/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8650 - loss: 0.3121 - val_accuracy: 0.7468 - val_loss: 0.6342\n",
            "Epoch 188/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8517 - loss: 0.3349 - val_accuracy: 0.7532 - val_loss: 0.6266\n",
            "Epoch 189/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8510 - loss: 0.3265 - val_accuracy: 0.7532 - val_loss: 0.6370\n",
            "Epoch 190/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8659 - loss: 0.3057 - val_accuracy: 0.7532 - val_loss: 0.6384\n",
            "Epoch 191/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8634 - loss: 0.2951 - val_accuracy: 0.7532 - val_loss: 0.6346\n",
            "Epoch 192/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8480 - loss: 0.3227 - val_accuracy: 0.7532 - val_loss: 0.6329\n",
            "Epoch 193/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8614 - loss: 0.3178 - val_accuracy: 0.7468 - val_loss: 0.6355\n",
            "Epoch 194/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8597 - loss: 0.3066 - val_accuracy: 0.7468 - val_loss: 0.6453\n",
            "Epoch 195/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8616 - loss: 0.3039 - val_accuracy: 0.7468 - val_loss: 0.6442\n",
            "Epoch 196/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8602 - loss: 0.3341 - val_accuracy: 0.7468 - val_loss: 0.6525\n",
            "Epoch 197/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8782 - loss: 0.2754 - val_accuracy: 0.7532 - val_loss: 0.6388\n",
            "Epoch 198/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8695 - loss: 0.3044 - val_accuracy: 0.7532 - val_loss: 0.6448\n",
            "Epoch 199/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8618 - loss: 0.3104 - val_accuracy: 0.7403 - val_loss: 0.6444\n",
            "Epoch 200/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8557 - loss: 0.3118 - val_accuracy: 0.7532 - val_loss: 0.6397\n",
            "Epoch 201/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8770 - loss: 0.3024 - val_accuracy: 0.7532 - val_loss: 0.6555\n",
            "Epoch 202/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8585 - loss: 0.3364 - val_accuracy: 0.7403 - val_loss: 0.6420\n",
            "Epoch 203/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8721 - loss: 0.2927 - val_accuracy: 0.7468 - val_loss: 0.6549\n",
            "Epoch 204/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8680 - loss: 0.2986 - val_accuracy: 0.7532 - val_loss: 0.6562\n",
            "Epoch 205/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8719 - loss: 0.2872 - val_accuracy: 0.7403 - val_loss: 0.6621\n",
            "Epoch 206/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8568 - loss: 0.3131 - val_accuracy: 0.7468 - val_loss: 0.6467\n",
            "Epoch 207/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8568 - loss: 0.3209 - val_accuracy: 0.7468 - val_loss: 0.6591\n",
            "Epoch 208/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8538 - loss: 0.3147 - val_accuracy: 0.7403 - val_loss: 0.6611\n",
            "Epoch 209/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8587 - loss: 0.3151 - val_accuracy: 0.7468 - val_loss: 0.6506\n",
            "Epoch 210/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8603 - loss: 0.3069 - val_accuracy: 0.7468 - val_loss: 0.6603\n",
            "Epoch 211/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8586 - loss: 0.3193 - val_accuracy: 0.7468 - val_loss: 0.6715\n",
            "Epoch 212/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8651 - loss: 0.2913 - val_accuracy: 0.7468 - val_loss: 0.6770\n",
            "Epoch 213/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8603 - loss: 0.3117 - val_accuracy: 0.7468 - val_loss: 0.6668\n",
            "Epoch 214/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8663 - loss: 0.3018 - val_accuracy: 0.7468 - val_loss: 0.6651\n",
            "Epoch 215/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8409 - loss: 0.3203 - val_accuracy: 0.7468 - val_loss: 0.6717\n",
            "Epoch 216/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8803 - loss: 0.3023 - val_accuracy: 0.7532 - val_loss: 0.6758\n",
            "Epoch 217/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8708 - loss: 0.3043 - val_accuracy: 0.7468 - val_loss: 0.6782\n",
            "Epoch 218/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8750 - loss: 0.2928 - val_accuracy: 0.7468 - val_loss: 0.6714\n",
            "Epoch 219/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8765 - loss: 0.2974 - val_accuracy: 0.7468 - val_loss: 0.6669\n",
            "Epoch 220/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8743 - loss: 0.2836 - val_accuracy: 0.7468 - val_loss: 0.6719\n",
            "Epoch 221/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8918 - loss: 0.2766 - val_accuracy: 0.7403 - val_loss: 0.6977\n",
            "Epoch 222/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8764 - loss: 0.2854 - val_accuracy: 0.7532 - val_loss: 0.6586\n",
            "Epoch 223/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8643 - loss: 0.2882 - val_accuracy: 0.7597 - val_loss: 0.6733\n",
            "Epoch 224/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8792 - loss: 0.2841 - val_accuracy: 0.7532 - val_loss: 0.6658\n",
            "Epoch 225/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8776 - loss: 0.2881 - val_accuracy: 0.7532 - val_loss: 0.6754\n",
            "Epoch 226/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8832 - loss: 0.2934 - val_accuracy: 0.7532 - val_loss: 0.6805\n",
            "Epoch 227/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8827 - loss: 0.2638 - val_accuracy: 0.7468 - val_loss: 0.6838\n",
            "Epoch 228/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8801 - loss: 0.2976 - val_accuracy: 0.7468 - val_loss: 0.6861\n",
            "Epoch 229/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8649 - loss: 0.3085 - val_accuracy: 0.7597 - val_loss: 0.6803\n",
            "Epoch 230/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8615 - loss: 0.2964 - val_accuracy: 0.7468 - val_loss: 0.6862\n",
            "Epoch 231/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8867 - loss: 0.2640 - val_accuracy: 0.7403 - val_loss: 0.7041\n",
            "Epoch 232/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8708 - loss: 0.2817 - val_accuracy: 0.7468 - val_loss: 0.6966\n",
            "Epoch 233/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8880 - loss: 0.2581 - val_accuracy: 0.7532 - val_loss: 0.6984\n",
            "Epoch 234/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8803 - loss: 0.2679 - val_accuracy: 0.7338 - val_loss: 0.7037\n",
            "Epoch 235/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8790 - loss: 0.2903 - val_accuracy: 0.7403 - val_loss: 0.6981\n",
            "Epoch 236/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8700 - loss: 0.2880 - val_accuracy: 0.7468 - val_loss: 0.7032\n",
            "Epoch 237/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8587 - loss: 0.2987 - val_accuracy: 0.7338 - val_loss: 0.7083\n",
            "Epoch 238/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8885 - loss: 0.2654 - val_accuracy: 0.7403 - val_loss: 0.7103\n",
            "Epoch 239/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8703 - loss: 0.2842 - val_accuracy: 0.7403 - val_loss: 0.7015\n",
            "Epoch 240/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8750 - loss: 0.2698 - val_accuracy: 0.7338 - val_loss: 0.7060\n",
            "Epoch 241/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8722 - loss: 0.2810 - val_accuracy: 0.7468 - val_loss: 0.7058\n",
            "Epoch 242/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8666 - loss: 0.2778 - val_accuracy: 0.7468 - val_loss: 0.7107\n",
            "Epoch 243/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8840 - loss: 0.2685 - val_accuracy: 0.7338 - val_loss: 0.7144\n",
            "Epoch 244/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8817 - loss: 0.2842 - val_accuracy: 0.7468 - val_loss: 0.7019\n",
            "Epoch 245/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8866 - loss: 0.2587 - val_accuracy: 0.7403 - val_loss: 0.7177\n",
            "Epoch 246/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8963 - loss: 0.2742 - val_accuracy: 0.7403 - val_loss: 0.7088\n",
            "Epoch 247/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8741 - loss: 0.2678 - val_accuracy: 0.7403 - val_loss: 0.7145\n",
            "Epoch 248/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8897 - loss: 0.2584 - val_accuracy: 0.7403 - val_loss: 0.7216\n",
            "Epoch 249/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8702 - loss: 0.2921 - val_accuracy: 0.7403 - val_loss: 0.7146\n",
            "Epoch 250/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8821 - loss: 0.2864 - val_accuracy: 0.7403 - val_loss: 0.7156\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8975 - loss: 0.2594 \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7272 - loss: 0.6694 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.8843648433685303\n",
            "Testing Accuracy: 0.7402597665786743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7dcb312a9d00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7dcb312a9d00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Precision: 0.631578947368421\n",
            "Recall: 0.6545454545454545\n",
            "F1-Score: 0.6428571428571429\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class (0: Non-Diabetic, 1: Diabetic): 0\n"
          ]
        }
      ]
    }
  ]
}